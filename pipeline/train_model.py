import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import joblib  # Pour sauvegarder le mod√®le

# --- CONFIGURATION ---
INPUT_FILE = "data_processed/energy_dataset_features.parquet"
MODEL_PATH = "pipeline/model_xgboost.pkl"

# Date de coupure : On s'entra√Æne sur tout avant, on teste sur tout apr√®s
# On garde les 2 derniers mois pour le test (Novembre-D√©cembre 2023 si tu as des donn√©es jusqu'√† 2024)
SPLIT_DATE = "2023-11-01" 

def train_forecasting_model():
    print("üß† Chargement des donn√©es...")
    df = pd.read_parquet(INPUT_FILE)
    
    # On d√©finit nos variables
    target = 'demand_mwh' # Ce qu'on veut pr√©dire
    
    # On enl√®ve la target et les colonnes de dates (la machine ne comprend pas "2023-01-01")
    # On garde toutes les features num√©riques cr√©√©es
    features = [col for col in df.columns if col not in ['datetime_utc', 'demand_mwh']]
    
    print(f"   Features utilis√©es ({len(features)}) : {features}")
    
    # 1. SPLIT TRAIN / TEST (Chronologique)
    print(f"‚úÇÔ∏è  D√©coupage Train/Test √† la date : {SPLIT_DATE}")
    train = df[df['datetime_utc'] < SPLIT_DATE].copy()
    test = df[df['datetime_utc'] >= SPLIT_DATE].copy()
    
    print(f"   Train set : {train.shape[0]} heures")
    print(f"   Test set  : {test.shape[0]} heures")
    
    X_train, y_train = train[features], train[target]
    X_test, y_test = test[features], test[target]
    
    # 2. ENTRAINEMENT (XGBoost)
    print("üî• Entra√Ænement du mod√®le XGBoost...")
    model = xgb.XGBRegressor(
        n_estimators=1000,    # Nombre d'arbres
        learning_rate=0.05,   # Vitesse d'apprentissage (plus petit = plus pr√©cis mais plus lent)
        max_depth=5,          # Profondeur des arbres
        early_stopping_rounds=50, # Arr√™te si √ßa ne s'am√©liore plus
        n_jobs=-1             # Utilise tous les coeurs du processeur
    )
    
    # On lui donne le test set pour qu'il surveille la qualit√© pendant l'entra√Ænement (eval_set)
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_test, y_test)],
        verbose=100 # Affiche le progr√®s toutes les 100 it√©rations
    )
    
    # 3. PREDICTION & EVALUATION
    print("üîÆ Pr√©dictions sur le Test Set...")
    predictions = model.predict(X_test)
    
    # M√©triques
    mae = mean_absolute_error(y_test, predictions)
    mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100
    
    print("\n" + "="*30)
    print("üìä R√âSULTATS DU MOD√àLE")
    print("="*30)
    print(f"   MAE (Erreur Moyenne Absolue) : {mae:.2f} MWh")
    print(f"   MAPE (Erreur Pourcentage)    : {mape:.2f} %")
    print("="*30)
    
    if mape < 5:
        print("‚úÖ EXCELLENT R√âSULTAT (< 5%) !")
    elif mape < 10:
        print("‚úÖ Bon r√©sultat (< 10%).")
    else:
        print("‚ö†Ô∏è R√©sultat moyen.")

    # 4. Feature Importance (Qu'est-ce qui a le plus compt√© ?)
    importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\nüèÜ Top 5 Features les plus importantes :")
    print(importance.head(5))
    
    # 5. Sauvegarde
    joblib.dump(model, MODEL_PATH)
    print(f"\nüíæ Mod√®le sauvegard√© sous : {MODEL_PATH}")

    # Petit bonus : Ajout des pr√©dictions dans le DataFrame test pour analyse future
    test['prediction'] = predictions
    test.to_csv("data_processed/test_predictions.csv", index=False)

if __name__ == "__main__":
    train_forecasting_model()